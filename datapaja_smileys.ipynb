{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little experiment in sentiment classification\n",
    "\n",
    "* Pick a large number of sentences that end with `:)` or `:(`\n",
    "* Train a classifier to try to distinguish among them\n",
    "* Pick the classifier's brain to see which are the distinguishing features\n",
    "\n",
    "# Step 1: Data preparation\n",
    "\n",
    "* Let us query for `:)` and `:(` and grab some data into files\n",
    "* We must make sure to remove the emoticons themselves from the documents\n",
    "    * **Why?**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python api_query.py -d 'Suomi24' --retmax 10000 '\":)\"' > happy_s24.conllu\n",
    "python api_query.py -d 'Suomi24' --retmax 10000 '\":(\"' > unhappy_s24.conllu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing\n",
    "\n",
    "* Get rid of the emoticons\n",
    "* Get rid of empty lines\n",
    "* Turn everything into lines of text, one per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ****** Happy   *******\n",
      "moni ihminen kaipailla tänään , niin minä kaivata rakkaus elämä\n",
      "mä kyllä Deturin entinen asiakas naurattaa\n",
      "huomata muuten , että mä FB : n kansi#kuva olla jokin sama , kun se paikka , joka nähdä\n",
      "olla se sellanen aurinkoinen päivitys\n",
      "niinpä ..\n",
      "Ok .\n",
      "Kittielle kiitos kiitos\n",
      "ja semmonen vielä että se lehdeton olla marsu herkku\n",
      "näköjään suhde#epäily nostaa taas pää\n",
      "mikään ei kuiteskaan olla täällä päässä kulahtaa ei olla myöskään elähtäny\n",
      "   ****** Uhanppy *******\n",
      "Kumpa pikkuinen alkaa taas vähän rauhoittua\n",
      "ihme nakutus kuulua nyt , jokin peli tai kone , joka yö ainakin kolme asti\n",
      "olla itse löysä ., mies ei tykätä\n",
      "nainen mutta nyt hän ei enää olla työ kun eräs henkilöstö vuokraus firma vähentää väki\n",
      "palsta ei enää täyttää tarkoitus\n",
      "ei olla kukaan ja ei olla kikkiä\n",
      "ei olla\n",
      "no joo olla se väärin mut mikä se mahtaa\n",
      "tuo hapatoiva sepustus antaa vain hyvä kuva mikä mummu korva välissä olla ; viha uskova ja se kohtaan joka kannattaa kristillisä perus#arvo\n",
      "vai , että samanlainen pitää ihminen muuttaa jotta hän voida olla samanlainen arvo - huhhuh mikä kehittymätön ajattelu\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# grep -v removes matching rows (opposite to bare grep)\n",
    "# conllu2text makes one sentence per row\n",
    "# '^$' is a pattern for empty row, grep -v removes it\n",
    "# head prints first 10 lines of whatever you give it\n",
    "# echo prints a message\n",
    "cat happy_s24.conllu | grep -v ':)' | python conllu2text.py -f LEMMA | grep -v '^$'  > happy_s24.txt\n",
    "cat unhappy_s24.conllu | grep -v ':(' | python conllu2text.py -f LEMMA | grep -v '^$'  > unhappy_s24.txt\n",
    "echo \"   ****** Happy   *******\"\n",
    "head happy_s24.txt\n",
    "echo \"   ****** Uhanppy *******\"\n",
    "head unhappy_s24.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10660 happy examples\n",
      "8159 unhappy examples\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "# Read the two files in Python\n",
    "happy=map(unicode.strip, codecs.open(\"happy_s24.txt\",\"r\",\"utf8\").readlines())\n",
    "unhappy=map(unicode.strip, codecs.open(\"unhappy_s24.txt\",\"r\",\"utf8\").readlines())\n",
    "\n",
    "#How many did we get?\n",
    "print len(happy), \"happy examples\"\n",
    "print len(unhappy), \"unhappy examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=72.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Turn the text into vectors that can be handled by the classifier\n",
    "vectorizer=TfidfVectorizer()\n",
    "data_matrix=vectorizer.fit_transform(happy+unhappy)\n",
    "# Give each document the target to be predicted\n",
    "labels=[\":)\"]*len(happy)+[\":(\"]*len(unhappy)\n",
    "\n",
    "# Keep 20% of the data aside for testing\n",
    "data_train,data_test,labels_train,labels_test=train_test_split(data_matrix, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the classifier on our data\n",
    "# C is an important parameter: the smaller, the fewer features will be used\n",
    "classifier=LinearSVC(C=0.05,penalty=\"L1\",dual=False)\n",
    "classifier.fit(data_train,labels_train)\n",
    "\n",
    "# And test its accuracy\n",
    "print \"Accuracy=%.2f%%\"%(classifier.score(X_test,Y_test)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Pick the classifier's brain\n",
    "\n",
    "* List features with extremely high (associated with positive labels) or extremely low (associated with negative labels) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ikävä -1.65595850566\n",
      "valitettavasti -1.6543497579\n",
      "ei -1.60435502889\n",
      "surullinen -1.57535242683\n",
      "harmi -1.5440953811\n",
      "enää -1.52270343786\n",
      "linkittää -1.40424162675\n",
      "ku -1.38572544054\n",
      "joulu -1.18803347064\n",
      "gt -1.17967630573\n",
      "pelottaa -1.11154470212\n",
      "mut -1.0870789438\n",
      "peljätä -1.05563467731\n",
      "tuntua -1.03099360532\n",
      "joutua -1.02617813819\n",
      "voi -1.02112936393\n",
      "huono -1.0137118077\n",
      "harmittaa -0.970605219623\n",
      "mutta -0.966156193311\n",
      "kuolla -0.963548248492\n",
      "mä -0.928661033032\n",
      "auttaa -0.828028862144\n",
      "jäädä -0.805290693775\n",
      "paha -0.787616167436\n",
      "kun -0.724629516498\n",
      "kamala -0.712055124427\n",
      "sairas -0.693497895989\n",
      "että -0.681729893822\n",
      "mennä -0.626297958452\n",
      "sen -0.60999723854\n",
      "------------------------\n",
      "yö 0.151515018012\n",
      "tykätä 0.160020334218\n",
      "ryssä 0.181119967931\n",
      "muu 0.215927541899\n",
      "kiittää 0.219757629872\n",
      "tarkoittaa 0.240287228188\n",
      "vastaus 0.244068271064\n",
      "hauska 0.254159296564\n",
      "sinä 0.266858513774\n",
      "tarvita 0.267891240611\n",
      "maa 0.279182715177\n",
      "kiva 0.282005040801\n",
      "tai 0.283502397026\n",
      "sielu 0.390673281397\n",
      "onneksi 0.404332333042\n",
      "hyvin 0.414838974048\n",
      "sä 0.446778004278\n",
      "ihana 0.45373010293\n",
      "100 0.503688264111\n",
      "uusi 0.512997314936\n",
      "täältä 0.53033746536\n",
      "rakkaus 0.530953145138\n",
      "onni 0.564509089744\n",
      "jos 0.59509860749\n",
      "kannattaa 0.629794875873\n",
      "sekä 0.636834997738\n",
      "terve 0.655797246414\n",
      "mukava 0.721604673021\n",
      "kiitos 0.788902742723\n",
      "hyvä 1.19310408989\n"
     ]
    }
   ],
   "source": [
    "# Print sorted by weight\n",
    "f_names=vectorizer.get_feature_names()\n",
    "sorted_by_weight=sorted(zip(classifier.coef_[0],f_names))\n",
    "# Thirty lowest\n",
    "for f_weight,f_name in sorted_by_weight[:30]:\n",
    "    print f_name, f_weight\n",
    "print \"------------------------\"\n",
    "# Thirty highest\n",
    "for f_weight,f_name in sorted_by_weight[-30:]:\n",
    "    print f_name, f_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: what have we got?\n",
    "\n",
    "* You tell me. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you try for yourself\n",
    "\n",
    "* I packed all the Python parts into the program `inf_features.py` which takes two files, one with positive examples, and one with negative examples, and lists for you the informative features. The examples are one per line, sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10660 examples of class 1\n",
      "8159 examples of class 2\n",
      "Accuracy=67.61%\n",
      "hyvä -1.34730566106\n",
      "kiitos -1.12922710688\n",
      "mukava -0.857320778375\n",
      "onni -0.776294498314\n",
      "sä -0.731208835058\n",
      "------------------------\n",
      "harmi 1.2812311198\n",
      "ku 1.3074499882\n",
      "ikävä 1.45702490104\n",
      "gt 1.53586089618\n",
      "ei 1.81224650642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2641: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python inf_features.py -n 5 -c 0.05 happy_s24.txt unhappy_s24.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have other Finnish corpora available as well\n",
    "    - `ff` 1 million sentences from Futis Forum messages\n",
    "    - `Fi-Parsebank-50M` 50 million sentences from the Internet\n",
    "    - `Suomi24` 10 million sentences from Suomi24\n",
    "* Can you see any difference between these for the same task?\n",
    "* Can you think of other document classes which you could try?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
